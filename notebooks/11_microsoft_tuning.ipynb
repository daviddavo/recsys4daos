{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm\n",
    "import ray\n",
    "from ray import train, tune\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from recsys4daos.model_selection import cvtt_open\n",
    "from recsys4daos.datasets import to_microsoft, filter_window_size\n",
    "from recsys4daos.models import LightGCNCustom\n",
    "from recsys4daos.utils import Timer\n",
    "import recsys4daos.utils.notebooks as nbu\n",
    "\n",
    "import recommenders\n",
    "if recommenders.__version__ == '1.2.0':\n",
    "    print(\"Ignoring warnings\")\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import paths\n",
    "\n",
    "nbu.print_versions('ray', 'tensorflow')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Others config\n",
    "SEED: int = 57\n",
    "RAY_RESULTS_PATH: Path = '~/ray_results3.11'\n",
    "\n",
    "# Dataset splits config\n",
    "ORG_NAME = 'Decentraland'\n",
    "SPLITS_FREQ = 'W-THU'  # Split weekly\n",
    "LAST_FOLDS = 10  # Use just last 10 splits\n",
    "SPLITS_NORMALIZE = True\n",
    "\n",
    "# Training config\n",
    "MAX_EPOCHS: int = 200\n",
    "EPOCHS_PER_ITER: int = 5\n",
    "SAMPLES_PER_SPLIT: int = 100\n",
    "# SAMPLES_PER_SPLIT: int = 10\n",
    "MAX_TIME_TOTAL_TRAIN: int = 300\n",
    "# MAX_TIME_TOTAL_TRAIN: int = 30\n",
    "OPTIM_METRIC: str = 'map@10'\n",
    "\n",
    "# Search space config\n",
    "MAX_EMBEDDING_DIM = 1024\n",
    "MAX_BATCH_SIZE = 10 # 2**10\n",
    "MIN_LR = 1e-4\n",
    "# WINDOW_SIZES = ['7d', '14d', '21d', '30d', '60d', '90d', '10YE']\n",
    "WINDOW_SIZES = ['21d', '30d', '60d', '90d', '10YE']\n",
    "GPUS = 16\n",
    "\n",
    "# Eval config\n",
    "K_RECOMMENDATIONS: List[int] = [1,3,5,10,15,100]\n",
    "METRICS: List[str] = [\"recall\", \"ndcg\", \"precision\", \"map\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAY_RESULTS_PATH = Path(RAY_RESULTS_PATH).expanduser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = paths.load_proposals(ORG_NAME)\n",
    "dfv = paths.load_votes(ORG_NAME)\n",
    "\n",
    "print(dfp.info())\n",
    "print(dfv.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = to_microsoft(dfv)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USE INTEGER INDEX\n",
    "# folds_dict = list(cvtt_open(df, SPLITS_FREQ, dfp, remove_not_in_train_col='userID'))\n",
    "# use_folds_idx = range(len(folds_dict))[-LAST_FOLDS:]\n",
    "\n",
    "# USE TIMESTAMP INDEX\n",
    "# Note: NO need to used OrderedDict, dict is ordered since Python 3.6\n",
    "folds_dict = { f.end.isoformat():f for f in cvtt_open(df, SPLITS_FREQ, dfp, remove_not_in_train_col='userID') }\n",
    "use_folds_idx = list(folds_dict.keys())[-LAST_FOLDS:]\n",
    "\n",
    "print(len(folds_dict), \"folds\")\n",
    "print(\"Using\", len(use_folds_idx), \"folds, from\", use_folds_idx[0], \"to\", use_folds_idx[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hparams = prepare_hparams(\n",
    "    model_type='lightgcn',\n",
    "    n_layers=3,\n",
    "    batch_size=512,\n",
    "    embed_size=64,\n",
    "    epochs=2,\n",
    "    learning_rate=0.001,\n",
    "    decay=0.001,\n",
    "    metrics=[\"recall\", \"ndcg\", \"precision\", \"map\"],\n",
    "    eval_epoch=2,\n",
    "    top_k=K_RECOMMENDATIONS[0],\n",
    "    save_model=False,\n",
    "    MODEL_DIR='./data/model/lightgcn/',\n",
    ")\n",
    "dataloader = ImplicitCF(train=folds_dict[use_folds_idx[0]].train, test=folds_dict[use_folds_idx[0]].test, seed=SEED)\n",
    "print(\"items:\", dataloader.n_items, \"user:\", dataloader.n_users)\n",
    "model = LightGCNCustom(data=dataloader, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()\n",
    "model.run_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.recommend_k_items(\n",
    "    dataloader.test, \n",
    "    top_k=3, \n",
    "    use_id=True, \n",
    "    remove_seen=True, \n",
    "    recommend_from=folds_dict[use_folds_idx[0]].open_proposals\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys4daos.evaluation import calculate_all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainLightGCN(tune.Trainable):\n",
    "    def setup(\n",
    "        self,\n",
    "        config: Dict[str, Any],\n",
    "        data,\n",
    "    ):\n",
    "        self.config = config\n",
    "        train, test, self.t, self.open_proposals = data\n",
    "        train_filtered = filter_window_size(train, self.t, config['window_size'])\n",
    "        self.dataloader = ImplicitCF(train=train_filtered, test=test, seed=SEED)\n",
    "        # Some experiments will run multiple times, but that's a price to pay for\n",
    "        # usability\n",
    "        self.real_batch_size = min(2**config['batch_size'], self.dataloader.n_users_in_train)\n",
    "\n",
    "        self.hparams = prepare_hparams(\n",
    "            model_type='lightgcn',\n",
    "            n_layers=config['conv_layers'],\n",
    "            batch_size=self.real_batch_size,\n",
    "            embed_size=config['embedding_dim'],\n",
    "            epochs=EPOCHS_PER_ITER,\n",
    "            learning_rate=config['learning_rate'],\n",
    "            decay=config['l2'],\n",
    "            metrics=METRICS,\n",
    "            eval_epoch=-1,\n",
    "            top_k=K_RECOMMENDATIONS[0],\n",
    "            save_model=False,\n",
    "            MODEL_DIR='./data/model/lightgcn/',\n",
    "        )\n",
    "        self.model = LightGCNCustom(self.hparams, self.dataloader, seed=SEED)\n",
    "        self.total_train = 0\n",
    "        self.total_eval = 0\n",
    "\n",
    "    @property\n",
    "    def iteration(self):\n",
    "        return self.model.epochs_done\n",
    "\n",
    "    @property\n",
    "    def training_iteration(self):\n",
    "        return self.model.epochs_done\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        As a rule of thumb, the execution time of step should be large enough to avoid overheads \n",
    "        (i.e. more than a few seconds), but short enough to report progress periodically \n",
    "        (i.e. at most a few minutes).\n",
    "        \"\"\"\n",
    "        assert EPOCHS_PER_ITER > 0\n",
    "\n",
    "        with Timer() as t_train:\n",
    "            for _ in range(EPOCHS_PER_ITER):\n",
    "                ret = self.model.fit_epoch()\n",
    "\n",
    "\n",
    "        with Timer() as t_rec:\n",
    "            recs = self.model.recommend_k_items(\n",
    "                self.dataloader.test, # Used only to get user ids\n",
    "                top_k=max(K_RECOMMENDATIONS),\n",
    "                use_id=True,\n",
    "                remove_seen=True,\n",
    "                recommend_from=self.open_proposals,\n",
    "            )\n",
    "        \n",
    "        eval_dict = {'model_'+k:v for k,v in zip(self.model.metrics, self.model.run_eval())}\n",
    "        eval_dict |= calculate_all_metrics(self.dataloader.test, recs, K_RECOMMENDATIONS)\n",
    "\n",
    "        self.total_train += t_train.time\n",
    "        self.total_eval += eval_dict['time_eval']\n",
    "        \n",
    "        return {\n",
    "            'real_batch_size': self.real_batch_size,\n",
    "            'iteration': self.iteration,\n",
    "            'loss': ret[0],\n",
    "            'mf_loss': ret[1],\n",
    "            'emb_loss': ret[2],\n",
    "            **eval_dict,\n",
    "            'time_train': t_train.time,\n",
    "            'time_rec': t_rec.time,\n",
    "            'time_total_train': self.total_train,\n",
    "            'time_total_test': self.total_eval,\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"model\")\n",
    "        self.model.saver.save(\n",
    "            sess=self.model.sess,\n",
    "            save_path=checkpoint_path,\n",
    "        )\n",
    "        return checkpoint_dir\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        self.model.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Big experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAY_RESULTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(os.uname().nodename)\n",
    "\n",
    "### SET TRAINING RESOURCES\n",
    "if os.uname().nodename == 'lamarck':\n",
    "    # assert torch.cuda.is_available()\n",
    "\n",
    "    NUM_SAMPLES = SAMPLES_PER_SPLIT\n",
    "    # Every run takes approx half a gig of vram (no optimizations)\n",
    "    # The RTX 4090 has 24GB so we can run the model about 48 times\n",
    "    resources_per_trial={\n",
    "        'cpu': 1,\n",
    "        'gpu': 1 / GPUS,\n",
    "    }\n",
    "else:\n",
    "    NUM_SAMPLES = 1\n",
    "    resources_per_trial={\n",
    "        'cpu': 1,\n",
    "        # It takes about 1.5 GiB with full training data, but I put a bit more because\n",
    "        # this notebook also takes a bit of memory\n",
    "        'memory': 2e9,\n",
    "    }\n",
    "print(resources_per_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getTunerOnFold(f_idx, points_to_evaluate = None):    \n",
    "    name = paths.lightgcn_ray_tune_fname(ORG_NAME, SPLITS_FREQ, SPLITS_NORMALIZE, OPTIM_METRIC, fold=f_idx)\n",
    "    experiments = list(RAY_RESULTS_PATH.glob(f'{name}_*'))\n",
    "    last_experiment = max(experiments, key=lambda x: x.stat().st_ctime) if experiments else None\n",
    "    f = folds_dict[f_idx]\n",
    "\n",
    "    dftrain,dftest,t,open_proposals = folds_dict[f_idx]\n",
    "    param_space = dict(\n",
    "        batch_size=tune.randint(6, MAX_BATCH_SIZE+1), # 64 - 2**MAX_BATCH_SIZE\n",
    "        embedding_dim=tune.lograndint(1, MAX_EMBEDDING_DIM, base=2),\n",
    "        conv_layers=tune.randint(1,5),\n",
    "        learning_rate=tune.qloguniform(MIN_LR, 1, 1e-4),\n",
    "        l2=tune.loguniform(1e-7, 1e-2, 1e-7),\n",
    "        window_size=tune.choice(WINDOW_SIZES),\n",
    "        # Just so it appears on the output\n",
    "        fold=f_idx,\n",
    "    )\n",
    "    \n",
    "    ### RESTORE EXPERIMENT OR CREATE A NEW ONE\n",
    "    if last_experiment and tune.Tuner.can_restore(last_experiment):\n",
    "        print(f\"Restoring last experiment: {last_experiment}\")\n",
    "        tuner = tune.Tuner.restore(\n",
    "            str(last_experiment),\n",
    "            trainable=tune.with_resources(\n",
    "                # tune.with_parameters(TrainLightGCN,  train=dftrain, test=dftest, open_proposals=open_proposals),\n",
    "                tune.with_parameters(TrainLightGCN, data=f),\n",
    "                resources_per_trial,\n",
    "            ),\n",
    "            restart_errored=True,\n",
    "            param_space=param_space,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"No experiment found for fold {f_idx}, creating new tuner with {NUM_SAMPLES} samples\")\n",
    "        search_alg = None\n",
    "        \n",
    "        search_alg = HyperOptSearch(\n",
    "            points_to_evaluate = points_to_evaluate,\n",
    "            random_state_seed=SEED,\n",
    "        )\n",
    "        # search_alg = tune.search.Repeater(search_alg, N_SPLITS-SKIP_SPLIT)\n",
    "        \n",
    "        tuner = tune.Tuner(\n",
    "            tune.with_resources(\n",
    "                # tune.with_parameters(TrainLightGCN,  train=dftrain, test=dftest, open_proposals=open_proposals),\n",
    "                tune.with_parameters(TrainLightGCN, data=folds_dict[f_idx]),\n",
    "                resources_per_trial,\n",
    "            ),\n",
    "            run_config=train.RunConfig(\n",
    "                stop={'training_iteration': MAX_EPOCHS/EPOCHS_PER_ITER, 'time_total_train': MAX_TIME_TOTAL_TRAIN},\n",
    "                name=name + f'_{dt.datetime.now().isoformat()}',\n",
    "                storage_path=RAY_RESULTS_PATH,\n",
    "                # failure_config=train.FailureConfig(fail_fast='raise'),\n",
    "                failure_config=train.FailureConfig(max_failures=3),\n",
    "            ),\n",
    "            param_space=param_space,\n",
    "            tune_config=tune.TuneConfig(\n",
    "                search_alg=search_alg,\n",
    "                num_samples=NUM_SAMPLES,\n",
    "                metric=OPTIM_METRIC,\n",
    "                mode='max',\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to display the progress bar in another cell because ray tune \"overwrites\" the previous output\n",
    "pbar = tqdm(total=len(use_folds_idx), desc='fold')\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "with out:\n",
    "    print(\"In this cell important output from the next cell will be shown\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def findConfig(rg):\n",
    "    for r in rg:\n",
    "        if r.config:\n",
    "            lbrc = last_best_result.config\n",
    "            if all((r.config[k] == v for k, v in last_best_result.config.items() if k != 'fold')):\n",
    "                return r\n",
    "            elif all((r.config[k] == v for k, v in last_best_result.config.items() if k != 'fold' and k != 'window_size')):\n",
    "                print(\"Possible coincidence:\", r.config, file=sys.stderr)\n",
    "\n",
    "    return None\n",
    "\n",
    "tuners = []\n",
    "results = []\n",
    "last_best_result = None\n",
    "pbar.reset()\n",
    "\n",
    "last_best_fold = None\n",
    "for prev_f_idx, f_idx in zip(it.chain([None], use_folds_idx), use_folds_idx):\n",
    "    with out:\n",
    "        best_prev_config = None\n",
    "        if last_best_result is not None:\n",
    "            best_prev_config = last_best_result.config.copy()\n",
    "            assert best_prev_config['fold'] == prev_f_idx\n",
    "            best_prev_config['fold'] = f_idx\n",
    "            print(f\"Also evaluating best_prev_config: {best_prev_config}\")\n",
    "            best_prev_config = [best_prev_config]\n",
    "    \n",
    "    t = getTunerOnFold(f_idx, best_prev_config)\n",
    "    tuners.append(t)\n",
    "\n",
    "    rg = t.fit()\n",
    "    assert rg.num_errors == 0, f\"There are {rg.num_errors} errors\"\n",
    "    assert rg.num_terminated >= NUM_SAMPLES, f'Some samples are not terminated ({rg.num_terminated} != {NUM_SAMPLES})'\n",
    "    results.append(rg)\n",
    "\n",
    "    # Assert that the prev config has been tried\n",
    "    if last_best_result is not None:\n",
    "        # if not any( \n",
    "        #     all((r.config[k] == v for k, v in last_best_result.config.items() if k != 'fold'))\n",
    "        #     for r in rg if r.config\n",
    "        # ):\n",
    "        if not findConfig(rg):\n",
    "            print(\"Best config:\", last_best_result.config)\n",
    "            assert False, f\"The best config from previous fold has not been tested in fold {f_idx}\"    \n",
    "        else:\n",
    "            logging.info(f'Fold {f_idx}. Best prev result was {last_best_result.path} and config has been found {findConfig(rg).path}')\n",
    "    \n",
    "    last_best_result = rg.get_best_result()\n",
    "    pbar.update()\n",
    "\n",
    "    print(f\"Finished training for fold {f_idx}\")\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "180306bca6774c0e8b10dac747c42992": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1fd17ae14826417abafe78e5546ca000": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6662d12b2f9a4f5b9fed318dc13665b9",
       "style": "IPY_MODEL_8c84139e84c24546870f2a767ac777d2",
       "value": "fold:   0%"
      }
     },
     "20194919966942c2bbb09735b6248927": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "37f427efbd4e400284a9cb9fc11afa8e": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_e5d905bd24b240dda99441557fd9d89a",
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": "In this cell important output from the next cell will be shown\n"
        }
       ]
      }
     },
     "6662d12b2f9a4f5b9fed318dc13665b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "75e0906ea3f14671abdc629a397c0d0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7b93a39414bf46caac87f7f26e77e2d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f609753c245a4c3b8099171d0e80dbe9",
       "style": "IPY_MODEL_180306bca6774c0e8b10dac747c42992",
       "value": " 0/10 [00:00&lt;?, ?it/s]"
      }
     },
     "8c84139e84c24546870f2a767ac777d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "accd29a0c93544d4a7423ccc9d18e423": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c19c7a2edd1044dfa3af146a904cc902": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1fd17ae14826417abafe78e5546ca000",
        "IPY_MODEL_d29dc6eed43b40d5beab63e9f400a881",
        "IPY_MODEL_7b93a39414bf46caac87f7f26e77e2d9"
       ],
       "layout": "IPY_MODEL_75e0906ea3f14671abdc629a397c0d0d"
      }
     },
     "d29dc6eed43b40d5beab63e9f400a881": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_20194919966942c2bbb09735b6248927",
       "max": 10,
       "style": "IPY_MODEL_accd29a0c93544d4a7423ccc9d18e423"
      }
     },
     "e5d905bd24b240dda99441557fd9d89a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "border_bottom": "1px solid black",
       "border_left": "1px solid black",
       "border_right": "1px solid black",
       "border_top": "1px solid black"
      }
     },
     "f609753c245a4c3b8099171d0e80dbe9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
